python train.py --scenario simple_push --num-adversaries 0
2018-10-11 14:12:58.764650: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
Using good policy maddpg and adv policy maddpg
Starting iterations...
steps: 24975, episodes: 1000, mean episode reward: -27.888465267506007, time: 10.108
steps: 49975, episodes: 2000, mean episode reward: -15.03752390114331, time: 14.025
steps: 74975, episodes: 3000, mean episode reward: -6.6330593146686, time: 13.749
steps: 99975, episodes: 4000, mean episode reward: -6.5245212093597535, time: 14.201
steps: 124975, episodes: 5000, mean episode reward: -6.496331506170197, time: 13.808
steps: 149975, episodes: 6000, mean episode reward: -6.384548390562311, time: 13.715
steps: 174975, episodes: 7000, mean episode reward: -6.432146591817591, time: 13.632
steps: 199975, episodes: 8000, mean episode reward: -6.500468841145957, time: 14.321
steps: 224975, episodes: 9000, mean episode reward: -6.392575845556416, time: 13.768
steps: 249975, episodes: 10000, mean episode reward: -6.397199305587446, time: 13.829
steps: 274975, episodes: 11000, mean episode reward: -6.454630861647506, time: 14.055
steps: 299975, episodes: 12000, mean episode reward: -6.598141789062574, time: 14.283
steps: 324975, episodes: 13000, mean episode reward: -6.4951988624077055, time: 13.983
steps: 349975, episodes: 14000, mean episode reward: -6.263125316329227, time: 14.036
steps: 374975, episodes: 15000, mean episode reward: -6.180070787617576, time: 13.905
steps: 399975, episodes: 16000, mean episode reward: -6.4873924256096, time: 14.312
steps: 424975, episodes: 17000, mean episode reward: -6.258751403669205, time: 13.911
steps: 449975, episodes: 18000, mean episode reward: -6.420890792116184, time: 13.751
steps: 474975, episodes: 19000, mean episode reward: -6.392637394445541, time: 13.782
steps: 499975, episodes: 20000, mean episode reward: -6.523551907927065, time: 13.936
steps: 524975, episodes: 21000, mean episode reward: -6.217645293115516, time: 14.072
steps: 549975, episodes: 22000, mean episode reward: -6.373313028102623, time: 13.926
steps: 574975, episodes: 23000, mean episode reward: -6.337491273007524, time: 13.997
steps: 599975, episodes: 24000, mean episode reward: -6.089430207201299, time: 14.245
steps: 624975, episodes: 25000, mean episode reward: -6.25334078342899, time: 13.848
steps: 649975, episodes: 26000, mean episode reward: -6.340120076276349, time: 14.539
steps: 674975, episodes: 27000, mean episode reward: -6.4238381115954395, time: 15.679
steps: 699975, episodes: 28000, mean episode reward: -6.447900092473546, time: 14.49
steps: 724975, episodes: 29000, mean episode reward: -6.546624990154258, time: 14.508
steps: 749975, episodes: 30000, mean episode reward: -6.412716434277063, time: 14.602
steps: 774975, episodes: 31000, mean episode reward: -6.464291767799811, time: 14.287
steps: 799975, episodes: 32000, mean episode reward: -6.31413018556687, time: 13.824
steps: 824975, episodes: 33000, mean episode reward: -6.22067106582081, time: 13.714
steps: 849975, episodes: 34000, mean episode reward: -6.262616714432006, time: 13.647
steps: 874975, episodes: 35000, mean episode reward: -6.3570204202682845, time: 13.647
steps: 899975, episodes: 36000, mean episode reward: -6.14123171168229, time: 13.731
steps: 924975, episodes: 37000, mean episode reward: -6.805296920459648, time: 13.716
steps: 949975, episodes: 38000, mean episode reward: -6.568194740757239, time: 13.817
steps: 974975, episodes: 39000, mean episode reward: -6.236927088507433, time: 13.809
steps: 999975, episodes: 40000, mean episode reward: -6.6130030105964615, time: 13.976
steps: 1024975, episodes: 41000, mean episode reward: -6.581264160933548, time: 14.12
steps: 1049975, episodes: 42000, mean episode reward: -6.706200791474447, time: 13.922
steps: 1074975, episodes: 43000, mean episode reward: -6.551036452579179, time: 13.753
steps: 1099975, episodes: 44000, mean episode reward: -6.611358045976863, time: 13.727
steps: 1124975, episodes: 45000, mean episode reward: -6.388275122912535, time: 13.706
steps: 1149975, episodes: 46000, mean episode reward: -6.5166603032990205, time: 13.707
steps: 1174975, episodes: 47000, mean episode reward: -6.325201328543782, time: 13.689
steps: 1199975, episodes: 48000, mean episode reward: -6.628812891734067, time: 13.816
steps: 1224975, episodes: 49000, mean episode reward: -6.686542902686997, time: 13.864
steps: 1249975, episodes: 50000, mean episode reward: -6.805573668855109, time: 13.804
steps: 1274975, episodes: 51000, mean episode reward: -6.584203983798451, time: 13.849
steps: 1299975, episodes: 52000, mean episode reward: -6.1427916425318525, time: 13.875
steps: 1324975, episodes: 53000, mean episode reward: -6.227749864181033, time: 13.882
steps: 1349975, episodes: 54000, mean episode reward: -6.546092008215928, time: 14.106
steps: 1374975, episodes: 55000, mean episode reward: -6.23279236129874, time: 13.804
steps: 1399975, episodes: 56000, mean episode reward: -6.283941155667417, time: 13.753
steps: 1424975, episodes: 57000, mean episode reward: -6.396243650252585, time: 13.947
steps: 1449975, episodes: 58000, mean episode reward: -6.346309268596702, time: 14.278
steps: 1474975, episodes: 59000, mean episode reward: -6.073747898263658, time: 14.097
steps: 1499975, episodes: 60000, mean episode reward: -6.3435754058276554, time: 14.122
