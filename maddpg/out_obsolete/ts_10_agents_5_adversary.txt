python train_ts.py --scenario simple_push --num-adversaries 5
2018-10-11 17:03:51.955938: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
Using good policy maddpg and adv policy maddpg
Starting iterations...
steps: 24975, episodes: 1000, mean episode reward: -212.5835413002623, agent episode reward: [-14.046539242563217, -17.522165662131677, -12.533280423581571, -12.708827469125648, -14.576463617251779, -28.747832316960377, -28.605753378580562, -27.183943809270506, -30.42652210164721, -26.232213279149764], time: 170.218
steps: 49975, episodes: 2000, mean episode reward: -103.49872651405404, agent episode reward: [-9.816575002407415, -10.19634107954667, -10.135334122530661, -9.577812335286769, -10.708770135472133, -9.92813979742155, -9.862178355917225, -11.513209768973505, -11.50752863196905, -10.252837284529068], time: 1224.548

steps: 74975, episodes: 3000, mean episode reward: -77.5673879104773, agent episode reward: [-8.027734389698137, -7.818442688050787, -7.892853780739793, -7.7414660741981836, -7.413084991143328, -7.7818017604567045, -7.805783988707889, -7.835910796639617, -7.734160552535205, -7.516148888307645], time: 1092.397
steps: 99975, episodes: 4000, mean episode reward: -76.47615998246049, agent episode reward: [-8.01386275577395, -7.294322034646613, -7.350418200519655, -7.833278554229801, -7.39753465489854, -8.02001673734687, -7.718283562396364, -7.659842755297274, -7.392302684097009, -7.796298043254416], time: 3138.137
steps: 124975, episodes: 5000, mean episode reward: -75.37413359523728, agent episode reward: [-7.60662454918219, -6.918942881267584, -7.181152736566053, -7.500156327595719, -7.171645147551779, -7.9886092448373525, -7.793759094895019, -7.529117977551764, -7.417265341560131, -8.266860294229675], time: 1091.246
steps: 149975, episodes: 6000, mean episode reward: -75.21533404759678, agent episode reward: [-7.941371612671594, -6.961412336656384, -7.056140437292768, -7.51865423223743, -6.677343106014712, -8.47626110157479, -7.365928438326741, -7.41955842003879, -8.267957232005822, -7.530707130777762], time: 1557.609
steps: 174975, episodes: 7000, mean episode reward: -75.88466123452038, agent episode reward: [-7.95498611276749, -6.638075304717422, -6.754507629604352, -7.675295690926671, -6.604570354314758, -7.987777050877248, -8.072954459596431, -7.4695101155430565, -9.065344488439354, -7.661640027733598], time: 9627.338
steps: 199975, episodes: 8000, mean episode reward: -77.7163804497254, agent episode reward: [-8.063152401227994, -6.601707960060072, -6.9154258881932185, -6.810144238623929, -6.485260511306641, -7.731627515765482, -7.835040216678702, -7.553286994894686, -12.098845711732771, -7.621889011241895], time: 1290.979
steps: 224975, episodes: 9000, mean episode reward: -79.11668304010415, agent episode reward: [-7.659403599126016, -6.348849612388565, -6.955997057459825, -5.969802784622309, -6.308609856359253, -7.673873992411656, -8.51909353495591, -7.915656654406046, -14.160462343538503, -7.604933604836066], time: 1157.642
steps: 249975, episodes: 10000, mean episode reward: -80.00508939951158, agent episode reward: [-6.112990613442177, -5.688960051876691, -6.575770366329022, -5.56630335474197, -5.714335321383006, -9.622036044818087, -9.682778388653325, -8.290890148279512, -15.247170039204331, -7.503855070783458], time: 1455.613
steps: 274975, episodes: 11000, mean episode reward: -72.53455970629508, agent episode reward: [-6.3020099127197815, -5.963520516009352, -7.133915779464903, -5.863130615962833, -5.764624068079287, -8.835815247160067, -8.813318767174064, -8.373512677760617, -7.906112094567232, -7.578600027396957], time: 1766.131
steps: 299975, episodes: 12000, mean episode reward: -72.60771281164675, agent episode reward: [-6.13535154009659, -5.494833816935154, -6.990904202692258, -5.728087808854618, -5.436504054754458, -9.556857318946328, -9.2479131027094, -8.103567727755385, -8.20364468110247, -7.710048557800099], time: 36474.422


